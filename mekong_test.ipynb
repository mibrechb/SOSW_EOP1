{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b5732-5120-4016-a04e-8eb9e045187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ee\n",
    "#import geemap\n",
    "import hvplot.pandas\n",
    "#import hvplot.xarray\n",
    "#import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shapely\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cda813-a3f9-41d3-925a-e633073fae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62337c9-a427-4688-9afa-6b3428749ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=(40, -100), zoom=4)\n",
    "Map.add_basemap(\"HYBRID\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50962626-732b-48b4-9853-6f0d95dc0f8c",
   "metadata": {},
   "source": [
    "## 1. Prep DSMP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e3b01-f69c-4404-8763-7620a52e112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from DSMP surves\n",
    "paths_data_q = list(Path(f'../mrc_webscrapper/outputs/csv/Sediment Concentration/').glob(f'*.csv'))\n",
    "paths_data_s = list(Path(f'../mrc_webscrapper/outputs/csv/Discharge/').glob(f'*.csv'))\n",
    "paths_data = paths_data_q + paths_data_s\n",
    "df_data = pd.DataFrame([])\n",
    "for path in paths_data:\n",
    "    df_temp = pd.read_csv(path, dtype={'station_code':'str'})\n",
    "    df_temp['date'] = pd.to_datetime(df_temp['date'])\n",
    "    df_temp['med_frq'] = np.median(np.diff(df_temp.date))\n",
    "    \n",
    "    df_data = pd.concat([df_data, df_temp])\n",
    "\n",
    "\n",
    "df_data_dsmp = df_data.loc[df_data.identifier.str.contains('DSMP')]\n",
    "df_dsmp_stations = df_data_dsmp.groupby('station_code').first()\n",
    "df_data_dsmp = df_data.loc[df_data.station_code.isin(df_dsmp_stations.index)]\n",
    "    \n",
    "gdf_stations = gpd.GeoDataFrame(df_dsmp_stations,\n",
    "                 crs={'init': 'epsg:4326'},\n",
    "                 geometry=df_dsmp_stations.apply(lambda row: shapely.geometry.Point((row.lon, row.lat)), axis=1)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715175a-4df3-485f-8e28-92efd1a0a594",
   "metadata": {},
   "source": [
    "### Plot DSMP stations on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4b11f-cafa-44ba-9ea3-5aa86cd332fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_labels = gdf_stations.groupby('station_name').first().reset_index().set_crs(\"EPSG:4326\").to_crs(\"EPSG:3857\")\n",
    "# gdf_labels['latitude_3857'] = gdf_labels.geometry.apply(lambda x: x.coords[0][1])\n",
    "# gdf_labels['longitude_3857'] = gdf_labels.geometry.apply(lambda x: x.coords[0][0])\n",
    "# labels = gdf_labels.hvplot.labels(x='longitude_3857', y='latitude_3857', text=\"station_name\", text_color='black')\n",
    "\n",
    "# gdf_stations.hvplot.points(geo=True, tiles='OSM', color='red', hover_cols=['station_name']) *\\\n",
    "#     labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d159793-eaf8-4cbe-89b6-126fe7e15d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "import time\n",
    "\n",
    "# Load DSMP station coords from Final Report\n",
    "path_csv = Path('mrc_data/dsmp_stations.csv')\n",
    "df_dsmp_stations_coords = pd.read_csv(path_csv, delimiter=';')\n",
    "\n",
    "path_transects = Path('mrc_data/dsmp_transects_drawn.csv')\n",
    "if not(path_transects.exists()):\n",
    "    transects = []\n",
    "    stations = []\n",
    "    for idx, row in df_dsmp_stations.iterrows():\n",
    "        match = df_dsmp_stations_coords.loc[df_dsmp_stations_coords['Station code']==row.name]\n",
    "        lon, lat = row.lon, row.lat\n",
    "        \n",
    "        if not(match.empty):\n",
    "            lat, lon = float(match.Latitude.values), float(match.Longitude.values)\n",
    "        print(f'({row.name}): ({lon}, {lat})')\n",
    "        ee_station = ee.Feature(ee.Algorithms.GeometryConstructors.Point([lon, lat]), {'station_id': row.name, 'station_name': row.station_name})\n",
    "        stations.append(ee_station)\n",
    "        Map.addLayer(ee_station, {'color': 'red'}, row.station_name)\n",
    "        Map.centerObject(ee_station, 10)\n",
    "        \n",
    "        wait = True\n",
    "        while wait: \n",
    "            if input('Transect added? (y/n)').lower()=='y': \n",
    "                wait = False    \n",
    "\n",
    "    for idx, station in enumerate(stations):\n",
    "        drawn_geom = Map.draw_features[idx].geometry()\n",
    "        ee_transect = stations[idx].setGeometry(drawn_geom)\n",
    "        transects.append(ee_transect)\n",
    "        \n",
    "    ee_transects = ee.FeatureCollection(transects)\n",
    "    gdf_transects = geemap.ee_to_gdf(ee_transects).reset_index(drop=True)\n",
    "    gdf_transects.to_csv('mrc_data/dsmp_transects_drawn.csv')\n",
    "        \n",
    "else:\n",
    "    path_transects = Path('mrc_data/dsmp_transects_drawn.csv')\n",
    "    df = pd.read_csv(path_transects)\n",
    "    gdf_transects =  gpd.GeoDataFrame(df, geometry=df['geometry'].apply(wkt.loads), crs='epsg:4326')\n",
    "    ee_transects = geemap.gdf_to_ee(gdf_transects)\n",
    "\n",
    "Map.addLayer(ee_transects, {'color':'red'}, 'Transects')\n",
    "Map.centerObject(ee_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27963a-6ef2-49e5-85a2-d01d03361d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_dsmp_stations.iterrows():\n",
    "    station_name = row.station_name\n",
    "    station_code = idx\n",
    "    print(f'({station_code}) {station_name}')\n",
    "    df_temp = df_data.loc[df_data.station_code==station_code]\n",
    "    df_dsmp_q = df_temp.loc[df_temp.identifier.str.contains('DSMP') & (df_temp.parameter=='Discharge')]\n",
    "    df_dsmp_s = df_temp.loc[df_temp.identifier.str.contains('DSMP') & (df_temp.parameter=='Sediment Concentration')]\n",
    "    df_wqm_q = df_temp.loc[~df_temp.identifier.str.contains('DSMP') & (df_temp.parameter=='Sediment Concentration')]\n",
    "    \n",
    "    # save datasets for each station\n",
    "    path_csv = Path(f'mrc_data/{station_code}')\n",
    "    path_csv.mkdir(parents=True, exist_ok=True)\n",
    "    df_dsmp_q.to_csv(f'mrc_data/{station_code}/{station_code}_DSMP_Q.csv')\n",
    "    df_dsmp_s.to_csv(f'mrc_data/{station_code}/{station_code}_DSMP_S.csv')\n",
    "    df_wqm_q.to_csv(f'mrc_data/{station_code}/{station_code}_WMQ_Q.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44686501-913a-4b52-8d32-adc60d7c0545",
   "metadata": {},
   "source": [
    "## 2. Get EO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdccfd-88a4-4b30-9148-3d4351521dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "}\n",
    "# Set timespan\n",
    "start_date, end_date = '2000-01-01', '2024-01-30'\n",
    "# Cloud masking (scene-based)\n",
    "cld_filt_thresh = 80        # Maximum image cloud cover percent allowed in image collection\n",
    "# water masking\n",
    "mask_water = True\n",
    "# Cloud masking (pixel-based, cloud score+ only)\n",
    "qa_band = 'cs_cdf'\n",
    "clear_thresh = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89397a-2d32-4bc8-b316-16107594484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import functions_process as funcs_process\n",
    "import functions_turbidity as funcs_turb\n",
    "import functions_sampling as funcs_sampling\n",
    "\n",
    "buffer = 90\n",
    "stations = ee_transects.map(lambda x: x.setGeometry(x.geometry().buffer(buffer)))\n",
    "Map.addLayer(stations, {'color': 'yellow'}, 'Sampling sites')\n",
    "\n",
    "for idx, row in geemap.ee_to_df(stations).iterrows():\n",
    "    name, id = row.station_name, row.station_id\n",
    "    print(f'{name} ({id})')\n",
    "    station = stations.filter(ee.Filter.eq('station_id', id))\n",
    "    station = station\n",
    "    \n",
    "    # get Rrs imagecolls\n",
    "    ic_msi = funcs_process.load_sr_imcoll(sensor='msi', start_date=start_date, end_date=end_date, mask_water=mask_water, bounds=station)\n",
    "    ic_oli = funcs_process.load_sr_imcoll(sensor='oli', start_date=start_date, end_date=end_date, mask_water=mask_water, bounds=station)\n",
    "    ic_etm = funcs_process.load_sr_imcoll(sensor='etm', start_date=start_date, end_date=end_date, mask_water=mask_water, bounds=station)\n",
    "    ic_all = ic_msi.merge(ic_oli).merge(ic_etm)\n",
    "    \n",
    "    # compute tsm features\n",
    "    ic_all = ic_all \\\n",
    "        .map(funcs_turb.calc_indices) \\\n",
    "        .map(funcs_turb.calc_band_ratios)\n",
    "\n",
    "    # merge imagecolls and sample\n",
    "    fc_all = ee.FeatureCollection(ic_all.map(funcs_sampling.sample_image(station))).flatten()\n",
    "\n",
    "    # export to drive\n",
    "    geemap.ee_export_vector_to_drive(\n",
    "        fc_all.filter(ee.Filter.gt('roi_coverage', 90)),\n",
    "        fileFormat='CSV', \n",
    "        folder=\"export_mekong_points_sr\",\n",
    "        description=f\"sr_samples_{name.replace(' ', '').lower()}_{id}\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ddd1b-dc56-4db7-9a3f-e8fd0857aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "pd_parser = lambda x: pd.to_datetime(x).tz_convert(None) if pd.to_datetime(x).tzinfo else pd.to_datetime(x)\n",
    "\n",
    "df_rs_all = pd.DataFrame([])\n",
    "df_dsmp_s_all = pd.DataFrame([])\n",
    "for idx, row in df_dsmp_stations.iterrows():\n",
    "    station_name = row.station_name\n",
    "    station_code = idx\n",
    "    df_rs = pd.read_csv(f'mrc_data/rrs_samples/rrs_samples_{''.join(station_name.lower().split())}_{station_code}.csv', parse_dates=['timestamp'], date_parser=pd_parser)\n",
    "    df_rs = df_rs.set_index('timestamp')\n",
    "    \n",
    "    df_dsmp_q = pd.read_csv(f'mrc_data/{station_code}/{station_code}_DSMP_Q.csv', parse_dates=['date'], date_parser=pd_parser)\n",
    "    df_dsmp_q_interp = df_dsmp_q[['date', 'value']].set_index('date').resample('1d').mean().interpolate(limit=7)\n",
    "    \n",
    "    df_dsmp_s = pd.read_csv(f'mrc_data/{station_code}/{station_code}_DSMP_S.csv', parse_dates=['date'], date_parser=pd_parser).set_index('date')\n",
    "    df_dsmp_s_interp = df_dsmp_s[['value']].resample('1d').mean().interpolate(limit=7)\n",
    "    \n",
    "    df_wqm_q = pd.read_csv(f'mrc_data/{station_code}/{station_code}_WMQ_Q.csv', parse_dates=['date'], date_parser=pd_parser)\n",
    "\n",
    "    # create matchups\n",
    "    df_s = df_dsmp_s.copy()\n",
    "    delta_dt_dry = 24 # hours\n",
    "    delta_dt_wet = 24\n",
    "    \n",
    "    n_matchups = 0\n",
    "    for idx, row in df_rs.iterrows():\n",
    "        timestamp = row.name\n",
    "        delta_dt = delta_dt_wet if (timestamp.month in [6,7,8,9,10,11]) else delta_dt_dry\n",
    "        t_start = timestamp - datetime.timedelta(hours=delta_dt)\n",
    "        t_end = timestamp + datetime.timedelta(hours=delta_dt)\n",
    "        matches = df_s.loc[(df_s.index <= t_end) & (df_s.index >= t_start)]\n",
    "        \n",
    "        if matches.shape[0] == 0:\n",
    "            value = np.nan\n",
    "            dt = pd.Timestamp('NaT')\n",
    "            dt_diff = pd.Timestamp('NaT')\n",
    "        elif matches.shape[0] == 1:\n",
    "            value = matches.iloc[0].value\n",
    "            dt = matches.iloc[0].name\n",
    "            dt_diff = abs(pd.to_datetime(matches.iloc[0].name)-timestamp)\n",
    "            n_matchups += 1\n",
    "        else:\n",
    "            matches.loc[:, 'dt_diff'] = abs(pd.to_datetime(matches.iloc[0].name)-timestamp)\n",
    "            matches = matches.sort_values('dt_diff')\n",
    "            value = matches.iloc[0].value \n",
    "            dt = matches.iloc[0].name\n",
    "            dt_diff = matches.iloc[0].dt_diff\n",
    "            n_matchups += 1\n",
    "\n",
    "\n",
    "        df_rs.loc[idx, 'season'] = 'wet' if (timestamp.month in [6,7,8,9,10,11]) else 'dry'\n",
    "        df_rs.loc[idx, 's'] = value\n",
    "        df_rs.loc[idx, 'dt_s'] = dt\n",
    "        df_rs.loc[idx, 'dt_diff'] = dt_diff\n",
    "\n",
    "    print(f'Found {n_matchups} for {station_name} ({station_code})')\n",
    "    df_rs['station_code'] = station_code\n",
    "    df_rs['station_name'] = station_name\n",
    "    df_rs_all = pd.concat([df_rs_all, df_rs])\n",
    "    df_dsmp_s_all = pd.concat([df_dsmp_s_all, df_dsmp_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60a703-1c20-439d-b1a6-925233fdf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_rs_all.copy()\n",
    "data = data.loc[data.CLOUD_COVER<85]\n",
    "data = data.loc[data.cloudiness_500m<0.2]\n",
    "data = data.loc[~np.isnan(data.s)]\n",
    "data = data.loc[data.s < 700]\n",
    "method = 'q_bin'\n",
    "data['q_bin'] = pd.qcut(data['s'], q=5, duplicates='drop')\n",
    "data['c_bin'] = pd.cut(data['s'], 4, duplicates='drop')\n",
    "min_group_sz = data.groupby(method).count()['system:time_start'].min()\n",
    "print(min_group_sz)\n",
    "data_strat = data.groupby(method).apply(lambda x: x.sample(n=50, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf67a9-06d4-4f6a-9179-561c1684305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "cmap = matplotlib.colors.ListedColormap(plt.cm.tab10.colors)\n",
    "\n",
    "data = data.loc[~np.isnan(data.s)]\n",
    "data = data_strat\n",
    "\n",
    "def f_GI_tss(x, c0, c1, c2):\n",
    "    Rb, Rg, Rr, Rnir = x\n",
    "    w1 = Rr/(Rr+Rnir)\n",
    "    w2 = Rnir/(Rr+Rnir)\n",
    "    GI_tss = c0 * (Rg/Rb) + c1 * w1 * (Rr/Rg) + c2 * w2 * (Rnir/Rg)\n",
    "    return GI_tss\n",
    "\n",
    "# get data\n",
    "metric = '_mean'\n",
    "Rb = data.apply(lambda x: x['B1'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B2'+metric], axis=1)\n",
    "Rg = data.apply(lambda x: x['B2'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B3'+metric], axis=1)\n",
    "Rr = data.apply(lambda x: x['B3'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B4'+metric], axis=1)\n",
    "Rnir = data.apply(lambda x: x['B8'+metric] if (str(x['platform']) == 'SENTINEL-2') \\\n",
    "                  else x['B4'+metric] if str(x['platform']) == 'LANDSAT-7' \\\n",
    "                  else x['B5'+metric], axis=1)\n",
    "\n",
    "x = (Rb, Rg, Rr, Rnir)\n",
    "y = data.s/1000\n",
    "\n",
    "p0 = (-0.008699050574443059, 0.09999999910518874, 0.09999999999982088)\n",
    "bounds_h = (10, 10, 10)\n",
    "bounds_l = (-10, -10, -10)\n",
    "\n",
    "# perform the fit\n",
    "params, cv = scipy.optimize.curve_fit(f_GI_tss, x, y, p0, bounds=(bounds_l, bounds_h), maxfev=10000000)\n",
    "c0, c1, c2 = params\n",
    "print(f'p0: {c0, c1, c2}')\n",
    "\n",
    "# determine quality of the fit\n",
    "squaredDiffs = np.square(y - f_GI_tss(x, c0, c1, c2))\n",
    "squaredDiffsFromMean = np.square(y - np.mean(y))\n",
    "rSquared = 1 - np.sum(squaredDiffs) / np.sum(squaredDiffsFromMean)\n",
    "print(f\"R² = {rSquared}\")\n",
    "\n",
    "# Calculae GITTS\n",
    "for idx, row in data.iterrows():\n",
    "    platform = row.platform   \n",
    "    Rb = row['B1'+metric] if platform == 'LANDSAT-7' else row['B2'+metric]\n",
    "    Rg = row['B2'+metric] if platform == 'LANDSAT-7' else row['B3'+metric]\n",
    "    Rr = row['B3'+metric] if platform == 'LANDSAT-7' else row['B4'+metric]\n",
    "    Rnir = row['B8'+metric] if platform == 'SENTINEL-2' \\\n",
    "        else row['B4'+metric] if platform == 'LANDSAT-7' \\\n",
    "        else row['B5'+metric]\n",
    "    x = (Rb, Rg, Rr, Rnir)\n",
    "    data.loc[idx, 'GI_tss'] = f_GI_tss(x, c0, c1, c2)    \n",
    "\n",
    "# plot the results\n",
    "colors = list(data.platform.apply(lambda x: cmap(0) if (x=='LANDSAT-8') else cmap(1) if (x=='LANDSAT-7') else cmap(2)).values)\n",
    "plt.grid(which='major', axis='y', zorder=-1.0)\n",
    "plt.scatter(data.GI_tss.values, y, color=colors, label=\"data\", alpha=1)\n",
    "#plt.plot(data.sort_values('GI_tss').GI_tss, data.sort_values('GI_tss').GI_tss, 'k--', label=\"data\")\n",
    "plt.title(\"Fitted GI Curve\")\n",
    "plt.ylabel(r'$TSM_{insitu}$ (g/L)')\n",
    "plt.xlabel(r'$GI_{TSS}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaa25d-5500-4043-8945-204a9a1c780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def powerFunc(x, a1, a2):\n",
    "    return a*(x**a2)\n",
    "\n",
    "metric = 'GI_tss'\n",
    "data = data.sort_values(metric)\n",
    "data = data.loc[data.s < 700]\n",
    "\n",
    "# get data\n",
    "ys = data.s\n",
    "xs = data[metric]\n",
    "\n",
    "# perform the fit\n",
    "p0 = (10, 4)\n",
    "bounds_h = (100, 100)\n",
    "bounds_l = (1, 1)\n",
    "\n",
    "params, cv = scipy.optimize.curve_fit(powerFunc, xs, ys, p0, bounds=(bounds_l, bounds_h), maxfev=100000)\n",
    "a1, a2 = params\n",
    "\n",
    "# determine quality of the fit\n",
    "squaredDiffs = np.square(ys - powerFunc(xs, a1, a2))\n",
    "squaredDiffsFromMean = np.square(ys - np.mean(ys))\n",
    "rSquared = 1 - np.sum(squaredDiffs) / np.sum(squaredDiffsFromMean)\n",
    "print(f'p0: {a1, a2}')\n",
    "print(f\"R² = {rSquared}\")\n",
    "print(f'RMSE = {np.sqrt(metrics.mean_squared_error(ys, powerFunc(xs, a1, a2)))}')\n",
    "\n",
    "# plot the results\n",
    "colors = list(data.platform.apply(lambda x: cmap(0) if (x=='LANDSAT-8') else cmap(1) if (x=='LANDSAT-7') else cmap(2)).values)\n",
    "plt.grid(which='major', axis='y', zorder=-1.0)\n",
    "plt.scatter(xs, ys, label=\"data\", color=colors)\n",
    "plt.plot(xs, powerFunc(xs, a1, a2), 'k--', label=\"fitted\")\n",
    "plt.title(\"Fitted GI Curve\")\n",
    "plt.ylabel(r'$TSM_{insitu}$ (g/L)')\n",
    "plt.xlabel(r'$GI_{TSS}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33399d3f-1458-4147-895d-1ed8db0d3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def monoExp(x, m, t, b):\n",
    "    return m * np.exp(t * x) + b\n",
    "\n",
    "def powerFunc(x, a1, a2):\n",
    "    return a*(x**a2)\n",
    "\n",
    "metric = 'GI_tss'\n",
    "data = data.sort_values(metric)\n",
    "data = data.loc[data.s < 700]\n",
    "\n",
    "# get data\n",
    "ys = data.s\n",
    "xs = data[metric]\n",
    "\n",
    "# perform the fit\n",
    "p0 = (1, 75, 0)\n",
    "bounds_h = (1, 100, 100)\n",
    "bounds_l = (-1, -0, -1)\n",
    "\n",
    "params, cv = scipy.optimize.curve_fit(monoExp, xs, ys, p0, bounds=(bounds_l, bounds_h), maxfev=100000)\n",
    "m, t, b = params\n",
    "\n",
    "# determine quality of the fit\n",
    "squaredDiffs = np.square(ys - monoExp(xs, m, t, b))\n",
    "squaredDiffsFromMean = np.square(ys - np.mean(ys))\n",
    "rSquared = 1 - np.sum(squaredDiffs) / np.sum(squaredDiffsFromMean)\n",
    "print(f'p0: {m, t, b}')\n",
    "print(f\"R² = {rSquared}\")\n",
    "print(f'RMSE = {np.sqrt(metrics.mean_squared_error(ys, monoExp(xs, m, t, b)))}')\n",
    "\n",
    "# plot the results\n",
    "colors = list(data.platform.apply(lambda x: cmap(0) if (x=='LANDSAT-8') else cmap(1) if (x=='LANDSAT-7') else cmap(2)).values)\n",
    "plt.grid(which='major', axis='y', zorder=-1.0)\n",
    "plt.scatter(xs, ys, label=\"data\", color=colors)\n",
    "plt.plot(xs, monoExp(xs, m, t, b), 'k--', label=\"fitted\")\n",
    "plt.title(\"Fitted GI Curve\")\n",
    "plt.ylabel(r'$TSM_{insitu}$ (g/L)')\n",
    "plt.xlabel(r'$GI_{TSS}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d738675-4e5e-42de-b9bb-e0bc1dd90208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tss(df, c0, c1, c2, x, m, t, b):\n",
    "\n",
    "    def monoExp(x, m, t, b):\n",
    "        return m * np.exp(t * x) + b\n",
    "    \n",
    "    metric = '_mean'\n",
    "    Rb = df.apply(lambda x: x['B1'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B2'+metric], axis=1)\n",
    "    Rg = df.apply(lambda x: x['B2'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B3'+metric], axis=1)\n",
    "    Rr = df.apply(lambda x: x['B3'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B4'+metric], axis=1)\n",
    "    Rnir = df.apply(lambda x: x['B8'+metric] if (str(x['platform']) == 'SENTINEL-2') \\\n",
    "                      else x['B4'+metric] if str(x['platform']) == 'LANDSAT-7' \\\n",
    "                      else x['B5'+metric], axis=1)\n",
    "    \n",
    "    w1 = Rr/(Rr+Rnir)\n",
    "    w2 = Rnir/(Rr+Rnir)\n",
    "    GI_tss = c0 * (Rg/Rb) + c1 * w1 * (Rr/Rg) + c2 * w2 * (Rnir/Rg)\n",
    "\n",
    "    df['GI_tss'] = GI_tss\n",
    "    df['tss_estimated'] = monoExp(GI_tss, m, t, b)\n",
    "    return df\n",
    "\n",
    "df_rs_all_out = calculate_tss(df_rs_all, c0, c1, c2, x, m, t, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baabb967-3adc-4d1f-8de5-cf69fecc1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "obs = 's'\n",
    "pred = 'tss_estimated'\n",
    "\n",
    "df = df_rs_all_out.copy()\n",
    "df = df.loc[~np.isnan(df[obs])]\n",
    "df = df.sort_values(obs)\n",
    "\n",
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[pred], df[obs])\n",
    "df['y_pred'] = intercept + slope * df[obs]\n",
    "\n",
    "# Calculate R² and RMSE\n",
    "r_squared = r_value**2\n",
    "rmse = np.sqrt(mean_squared_error(df[obs], df[pred]))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[obs], df[pred], label='Data')\n",
    "plt.plot(df[obs], df['y_pred'], color='red', label='Linear regression')\n",
    "\n",
    "# Adding text annotations for R² and RMSE\n",
    "plt.text(0.05, 0.95, f'R² = {r_squared:.2f}', fontsize=12, transform=plt.gca().transAxes)\n",
    "plt.text(0.05, 0.90, f'RMSE = {rmse:.2f}', fontsize=12, transform=plt.gca().transAxes)\n",
    "\n",
    "# Final touches\n",
    "plt.ylabel(r'$TSM_{insitu}$ (g/L)')\n",
    "plt.xlabel(r'$TSM_{eo}$ (g/L)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7091a2-b69d-4de9-81c7-f277b8ac9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rs_all_out.hvplot(y='tss_estimated', groupby='station_code') *\\\n",
    "df_rs_all_out.hvplot.scatter(y='tss_estimated', groupby='station_code') *\\\n",
    "df_dsmp_s_all.hvplot.scatter(y='value', groupby='station_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0ca52-127e-460f-b3e5-ba34b61c1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rs_all.copy()\n",
    "df = df.loc[~np.isnan(df.s)]\n",
    "metric = '_mean'\n",
    "df['blue'] = df.apply(lambda x: x['B1'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B2'+metric], axis=1)\n",
    "df['green'] = df.apply(lambda x: x['B2'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B3'+metric], axis=1)\n",
    "df['red'] = df.apply(lambda x: x['B3'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B4'+metric], axis=1)\n",
    "df['nir'] = df.apply(lambda x: x['B8'+metric] if (str(x['platform']) == 'SENTINEL-2') \\\n",
    "                  else x['B4'+metric] if str(x['platform']) == 'LANDSAT-7' \\\n",
    "                  else x['B5'+metric], axis=1)\n",
    "\n",
    "df_in = df[['blue', 'green', 'red', 'nir', 's']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaba7aa-3dfe-4ba2-8d60-1511dd61b090",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca7b4f-146b-4b4b-8fb0-47853ac19ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eae4b8-c979-41b1-a369-ce331f2716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rs_all.copy()\n",
    "\n",
    "# additional filters\n",
    "df = df.loc[df.CLOUD_COVER<75]\n",
    "df = df.loc[df.cloudiness_500m<0.2]\n",
    "df = df.loc[df.s < 700]\n",
    "\n",
    "df = df.loc[~np.isnan(df.s)]\n",
    "metric = '_mean'\n",
    "df['blue'] = df.apply(lambda x: x['B1'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B2'+metric], axis=1)\n",
    "df['green'] = df.apply(lambda x: x['B2'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B3'+metric], axis=1)\n",
    "df['red'] = df.apply(lambda x: x['B3'+metric] if str(x['platform']) == 'LANDSAT-7' else x['B4'+metric], axis=1)\n",
    "df['nir'] = df.apply(lambda x: x['B8'+metric] if (str(x['platform']) == 'SENTINEL-2') \\\n",
    "                  else x['B4'+metric] if str(x['platform']) == 'LANDSAT-7' \\\n",
    "                  else x['B5'+metric], axis=1)\n",
    "\n",
    "df_in = df[['blue', 'green', 'red', 'nir', 's']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d999f2-d17c-4e17-a642-87cdfb58a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# prep data\n",
    "obs_column = 's'\n",
    "features = df._get_numeric_data().drop(columns=[obs_column, 'system:time_start', 'CLOUD_COVER'])\n",
    "labels = df._get_numeric_data()[obs_column]\n",
    "\n",
    "# Setup model\n",
    "n_estimators = 100\n",
    "model = xgb.XGBRegressor(n_estimators=n_estimators)\n",
    "\n",
    "# *-*-* k-fold cv\n",
    "n_splits = 5\n",
    "print(f'{n_splits}-fold Cross-validation:')\n",
    "cv = RepeatedKFold(n_splits=n_splits, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(model, features, labels, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force scores to be positive\n",
    "scores = abs(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "\n",
    "# *-*-* Train-test-split validation\n",
    "print(f'Tain-test-split Validation:')\n",
    "\n",
    "# statify splits\n",
    "q_bin = pd.qcut(labels, q=25, duplicates='drop')\n",
    "c_bin = pd.cut(labels, 4, duplicates='drop')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.50, random_state=1, stratify=c_bin)\n",
    "feature_names = features.columns.values\n",
    "\n",
    "model.fit(X_train, y_train, eval_metric=\"error\", verbose=True)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# evaluate predictions\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean Absolute Error:', mae)\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
    "plt.xlabel(r'$TSM_{insitu}$ (mg/L)')\n",
    "plt.ylabel(r'$TSM_{rs}$ (mg/L)')\n",
    "plt.title('TSM Model validation\\n(XGBOOST Regressor)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e401c74-6bd0-40cd-a53b-27ce2c826923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance using built-in function\n",
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(model, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e653b1-cebc-4421-a272-1163a5574d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
